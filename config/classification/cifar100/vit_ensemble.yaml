coslr: true
endlr: 0.0
dataset:
  batch_size: 128
  dataset: cifar100
  dataroot: ./data/CIFAR100
  img_size: 224
  num_workers: 8
  use_gpu: true
networks:
  def_file: ./models/ViT_Ensemble_New.py
  params: {model_name: vit_small_patch16_224, pretrained: false, num_classes: 100, selected_layers: [7, 9], aux_depth: 2, normalized: false, scale: 30}

model_dir: null
optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0001}

training_opt:
  log_dir: ./logs/cifar100/ViT_Ensemble
  num_epochs: 10000
  num_steps: 50000
  warmup_steps: 500
  mixed_loss: true
  alpha: 0.2
  base_weight: 1
  max_grad_norm: 1
  num_accmutations: 1
  gamma: 1
  mixer_type: mixup
