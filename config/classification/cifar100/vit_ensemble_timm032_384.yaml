coslr: true
endlr: 0.0
dataset:
  batch_size: 32
  dataset: cifar100
  dataroot: ./data/CIFAR100
  img_size: 384
  num_workers: 8
  use_gpu: true
networks:
  def_file: ./models/ViT_Ensemble_Timm032_v2.py
  params: {model_name: vit_large_patch16_384, num_classes: 100, pretrained: true, global_pool: true, selected_layers: [7, 9], normalized: false, aux_depth: 2, scale: 30}

model_dir: null
optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0001}

training_opt:
  log_dir: ./logs/cifar100/ViT_Ensemble_Timm032
  num_epochs: 10000
  num_steps: 5000
  warmup_steps: 500
  mixed_loss: true
  alpha: 1
  base_weight: 1
  max_grad_norm: 1
  num_accmutations: 8
  gamma: 2
  mixer_type: mixup
