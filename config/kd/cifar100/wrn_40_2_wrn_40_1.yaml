coslr: true
endlr: 0.0
dataset:
  batch_size: 64
  dataset: cifar100
  dataroot: ./data/CIFAR100
  img_size: 32
  num_workers: 8
  use_gpu: true
networks:
  teacher: "wrn_40_2"
  student: 
    def_file: ./models/KD/cifar/wrn_ensemble.py
    params: {model_name: "wrn_40_1", num_classes: 100}


model_dir: null
optim_params: {lr: 0.05, momentum: 0.9, weight_decay: 0.0005}

training_opt:
  log_dir: ./logs/kd/cifar100/wrn_40_2_wrn_40_1
  num_epochs: 240
  warmup_epoch: 5
  num_accmutations: 1
  milestones: [140, 180, 220]
  mixed_loss: true
  alpha: 1
  mixer_type: mixup
  base_weight: 0.5
  tempture: 4
  gamma: 1.0
  ce_weight: 1
  kd_weight: 1
